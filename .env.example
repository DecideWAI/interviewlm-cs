# Database
# PostgreSQL connection string
# For local development: postgresql://user:password@localhost:5432/interviewlm
# For AWS RDS: postgresql://user:password@your-rds-endpoint.region.rds.amazonaws.com:5432/interviewlm
# For GCP Cloud SQL: postgresql://user:password@your-cloud-sql-ip:5432/interviewlm
DATABASE_URL="postgresql://user:password@localhost:5432/interviewlm"

# NextAuth.js
# Generate a random secret: openssl rand -base64 32
NEXTAUTH_SECRET="your-nextauth-secret-here"
NEXTAUTH_URL="http://localhost:3000"

# OAuth Providers
# GitHub OAuth App: https://github.com/settings/developers
GITHUB_CLIENT_ID="your-github-client-id"
GITHUB_CLIENT_SECRET="your-github-client-secret"

# Google OAuth App: https://console.cloud.google.com/apis/credentials
GOOGLE_CLIENT_ID="your-google-client-id"
GOOGLE_CLIENT_SECRET="your-google-client-secret"

# Optional: Email Provider (for magic links, password reset)
# You can use AWS SES, SendGrid, or other SMTP services
# EMAIL_SERVER="smtp://username:password@smtp.example.com:587"
# EMAIL_FROM="noreply@interviewlm.com"

# Anthropic Claude API
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY="your-anthropic-api-key-here"

# Modal AI Sandbox
# Get your token from: https://modal.com/settings/tokens
MODAL_TOKEN_ID="your-modal-token-id"
MODAL_TOKEN_SECRET="your-modal-token-secret"
# Deploy modal_executor.py and copy the endpoint URLs here
MODAL_EXECUTE_URL="https://your-username--interviewlm-executor-execute.modal.run"
MODAL_WRITE_FILE_URL="https://your-username--interviewlm-executor-write-file.modal.run"
MODAL_READ_FILE_URL="https://your-username--interviewlm-executor-read-file.modal.run"
MODAL_LIST_FILES_URL="https://your-username--interviewlm-executor-list-files.modal.run"
MODAL_EXECUTE_COMMAND_URL="https://your-username--interviewlm-executor-execute-command.modal.run"

# Resend Email Service
# Get your API key from: https://resend.com/api-keys
RESEND_API_KEY="re_your_api_key"
RESEND_FROM_EMAIL="onboarding@resend.dev"  # or your verified domain

# Paddle Payment Gateway
# Get credentials from: https://vendors.paddle.com/authentication
PADDLE_VENDOR_ID="your-vendor-id"
PADDLE_API_KEY="your-api-key"
PADDLE_PUBLIC_KEY="your-public-key"
PADDLE_WEBHOOK_SECRET="your-webhook-secret"
PADDLE_ENVIRONMENT="sandbox"  # or "production"
PADDLE_PRODUCT_SINGLE="pri_01xxx"  # Product ID for single assessment
PADDLE_PRODUCT_MEDIUM="pri_01yyy"  # Product ID for 50 assessments
PADDLE_PRODUCT_ENTERPRISE="pri_01zzz"  # Product ID for 500 assessments

# AWS S3 (for session recordings)
AWS_REGION="us-east-1"
AWS_ACCESS_KEY_ID="your-aws-access-key"
AWS_SECRET_ACCESS_KEY="your-aws-secret-key"
AWS_S3_BUCKET="interviewlm-sessions"

# Google Cloud Storage (for session recordings and file content)
# Required for file content storage in replay feature
# Get credentials from: https://console.cloud.google.com/iam-admin/serviceaccounts
GOOGLE_CLOUD_PROJECT="your-project-id"
GCS_BUCKET="interviewlm-sessions"
# Enable GCS uploads for file snapshots (default: false)
GCS_ENABLED="false"
# For local development: path to service account JSON key file
# In production (Cloud Run, GKE): uses default service account automatically
GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account-key.json"

# Internal API Communication
# Shared secret between LangGraph agents and Next.js API for server-to-server calls
# Generate with: openssl rand -hex 32
INTERNAL_API_KEY="your-internal-api-key"
# Next.js URL for LangGraph to call back (file snapshot capture, etc)
NEXTJS_INTERNAL_URL="http://localhost:3000"

# Optional: Redis (for caching, rate limiting, BullMQ workers)
REDIS_URL="redis://localhost:6379"

# Code Streaming Feature
# Enable real-time code streaming from AI to editor (default: true)
ENABLE_CODE_STREAMING="true"

# Optional: Monitoring and Analytics
# SENTRY_DSN="your-sentry-dsn"
# ANALYTICS_ID="your-analytics-id"

# LangSmith Observability (for tracing Claude API calls)
# Get your API key from: https://smith.langchain.com/
LANGSMITH_TRACING="true"
LANGSMITH_API_KEY="your-langsmith-api-key"
LANGSMITH_PROJECT="interviewlm"
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"

# LangGraph API
# URL of the LangGraph SDK server (for coding agent and question evaluation)
# Start with: cd langgraph-agents && langgraph dev
LANGGRAPH_API_URL="http://localhost:2024"

# Node Environment
NODE_ENV="development"
